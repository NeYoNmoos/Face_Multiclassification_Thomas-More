{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 15:20:29.436314: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-10 15:20:29.715586: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-10 15:20:29.717060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-10 15:20:30.778626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Dataset loaded: 611 images.\n",
      "Label Map: {0: 'matthias', 1: 'lasse', 2: 'akif', 3: 'bart', 4: 'florian', 5: 'daiane', 6: 'konrad', 7: 'senne', 8: 'michiel', 9: 'seppe', 10: 'youssef', 11: 'raul', 12: 'alper', 13: 'nelli'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FaceNet128dClient' object has no attribute 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m base_model \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mbuild_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Add a custom classification layer\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(base_model\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m     63\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FaceNet128dClient' object has no attribute 'input'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from deepface import DeepFace\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to preprocess images for DeepFace\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    return img_resized\n",
    "\n",
    "# Path to the cropped faces folder\n",
    "data_folder = \"../data/faces3\"\n",
    "\n",
    "def create_face_dataset(data_folder):\n",
    "    face_dataset = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    current_label = 0\n",
    "\n",
    "    for person_name in os.listdir(data_folder):\n",
    "        person_folder = os.path.join(data_folder, person_name)\n",
    "        if os.path.isdir(person_folder):\n",
    "            label_map[current_label] = person_name\n",
    "            for filename in os.listdir(person_folder):\n",
    "                img_path = os.path.join(person_folder, filename)\n",
    "                processed_img = preprocess_image(img_path)\n",
    "                if processed_img is not None:\n",
    "                    face_dataset.append(processed_img.flatten())\n",
    "                    labels.append(current_label)\n",
    "            current_label += 1\n",
    "    \n",
    "    return np.array(face_dataset), np.array(labels), label_map\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "images, labels, label_map = create_face_dataset(data_folder)\n",
    "print(f\"Dataset loaded: {len(images)} images.\")\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Apply PCA to create Eigenfaces\n",
    "pca = PCA(n_components=100, whiten=True, random_state=42)\n",
    "images_pca = pca.fit_transform(images)\n",
    "\n",
    "# Prepare labels for training\n",
    "num_classes = len(label_map)\n",
    "labels_categorical = to_categorical(labels, num_classes)\n",
    "\n",
    "# Load the DeepFace Facenet model\n",
    "base_model = DeepFace.build_model(\"Facenet\")\n",
    "\n",
    "# Add a custom classification layer\n",
    "input_layer = base_model.input\n",
    "x = Dense(64, activation='relu')(base_model.output)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training model...\")\n",
    "history = model.fit(images_pca, labels_categorical, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"../data/deepface_facenet_model.h5\"\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict using the model\n",
    "def predict_faces(test_folder, model, pca, label_map):\n",
    "    results = []\n",
    "\n",
    "    for filename in sorted(os.listdir(test_folder)):\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "        processed_img = preprocess_image(img_path)\n",
    "        if processed_img is None:\n",
    "            continue\n",
    "\n",
    "        img_pca = pca.transform([processed_img.flatten()])\n",
    "        predictions = model.predict(img_pca)\n",
    "        predicted_label = np.argmax(predictions)\n",
    "        person_name = label_map[predicted_label]\n",
    "\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"predicted_label\": person_name,\n",
    "            \"confidence\": np.max(predictions)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Paths for prediction\n",
    "test_folder = \"../data/faces4_test\"\n",
    "results = predict_faces(test_folder, model, pca, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group results by image\n",
    "def group_results_by_image(results):\n",
    "    grouped_data = {}\n",
    "    for result in results:\n",
    "        base_filename = result[\"filename\"].split(\"_face\")[0]\n",
    "        if base_filename not in grouped_data:\n",
    "            grouped_data[base_filename] = []\n",
    "        grouped_data[base_filename].append(result[\"predicted_label\"].lower())\n",
    "\n",
    "    grouped_results = [{\"filename\": filename, \"predicted_labels\": labels} for filename, labels in grouped_data.items()]\n",
    "    return grouped_results\n",
    "\n",
    "grouped_results = group_results_by_image(results)\n",
    "\n",
    "# Create submission file\n",
    "def create_submission_csv(grouped_results, output_csv_path, test_images_folder):\n",
    "    all_filenames = sorted(\n",
    "        [os.path.splitext(filename)[0] for filename in os.listdir(test_images_folder) \n",
    "         if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    )\n",
    "\n",
    "    grouped_dict = {group[\"filename\"].split('.')[0]: \";\".join(group[\"predicted_labels\"]) for group in grouped_results}\n",
    "\n",
    "    submission_data = []\n",
    "    for filename in all_filenames:\n",
    "        label_name = grouped_dict.get(filename, \"nothing\")\n",
    "        submission_data.append({\"image\": filename, \"label_name\": label_name})\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Submission file saved to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "test_images_folder = \"../data/images/test_images/cleaned_images\"\n",
    "output_csv_path = \"../submission.csv\"\n",
    "create_submission_csv(grouped_results, output_csv_path, test_images_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Dataset loaded: 611 images.\n",
      "Label Map: {0: 'matthias', 1: 'lasse', 2: 'akif', 3: 'bart', 4: 'florian', 5: 'daiane', 6: 'konrad', 7: 'senne', 8: 'michiel', 9: 'seppe', 10: 'youssef', 11: 'raul', 12: 'alper', 13: 'nelli'}\n",
      "Extracting embeddings...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Confirm that opencv is installed on your environment! Expected path ', '/home/neyon/anaconda3/lib/python3.9/site-packages/data/haarcascade_frontalface_default.xml', ' violated.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Extract embeddings using DeepFace\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mextract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Apply PCA for dimensionality reduction\u001b[39;00m\n\u001b[1;32m     59\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, whiten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mextract_embeddings\u001b[0;34m(images, model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m---> 22\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/DeepFace.py:418\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing, max_faces)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresent\u001b[39m(\n\u001b[1;32m    360\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    361\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     max_faces: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    369\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Represent facial images as multi-dimensional vector embeddings.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            to 'skip', the confidence will be 0 and is nonsensical.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_faces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_faces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/modules/representation.py:76\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing, max_faces)\u001b[0m\n\u001b[1;32m     74\u001b[0m target_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector_backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     img_objs \u001b[38;5;241m=\u001b[39m \u001b[43mdetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# skip\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Try load. If load error, will raise exception internal\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     img, _ \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mload_image(img_path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/modules/detection.py:95\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[1;32m     93\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m [DetectedFace(img\u001b[38;5;241m=\u001b[39mimg, facial_area\u001b[38;5;241m=\u001b[39mbase_region, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/modules/detection.py:206\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(detector_backend, img, align, expand_percentage)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mDetect face(s) from a given image\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    - confidence (float): The confidence score associated with the detected face.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 206\u001b[0m face_detector: Detector \u001b[38;5;241m=\u001b[39m \u001b[43mmodeling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface_detector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# validate expand percentage score\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand_percentage \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/modules/modeling.py:96\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(task, model_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m model \u001b[38;5;241m=\u001b[39m models[task]\u001b[38;5;241m.\u001b[39mget(model_name)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[0;32m---> 96\u001b[0m     cached_models[task][model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model_name passed - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/models/face_detection/OpenCv.py:14\u001b[0m, in \u001b[0;36mOpenCvClient.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/models/face_detection/OpenCv.py:23\u001b[0m, in \u001b[0;36mOpenCvClient.build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mBuild opencv's face and eye detector models\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    model (dict): including face_detector and eye_detector keys\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m detector \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 23\u001b[0m detector[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_detector\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhaarcascade\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m detector[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meye_detector\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__build_cascade(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaarcascade_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detector\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/deepface/models/face_detection/OpenCv.py:143\u001b[0m, in \u001b[0;36mOpenCvClient.__build_cascade\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m     face_detector_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(opencv_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(face_detector_path):\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfirm that opencv is installed on your environment! Expected path \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    145\u001b[0m             face_detector_path,\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m violated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m     detector \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(face_detector_path)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaarcascade_eye\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: ('Confirm that opencv is installed on your environment! Expected path ', '/home/neyon/anaconda3/lib/python3.9/site-packages/data/haarcascade_frontalface_default.xml', ' violated.')"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Function to preprocess images for DeepFace\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    return img_resized\n",
    "\n",
    "# Function to extract embeddings using DeepFace\n",
    "def extract_embeddings(images, model_name=\"Facenet\"):\n",
    "    embeddings = []\n",
    "    for img in images:\n",
    "        embedding = DeepFace.represent(img, model_name=model_name, enforce_detection=False)\n",
    "        embeddings.append(embedding[0][\"embedding\"])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Path to the cropped faces folder\n",
    "data_folder = \"../data/faces3\"\n",
    "\n",
    "def create_face_dataset(data_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    current_label = 0\n",
    "\n",
    "    for person_name in os.listdir(data_folder):\n",
    "        person_folder = os.path.join(data_folder, person_name)\n",
    "        if os.path.isdir(person_folder):\n",
    "            label_map[current_label] = person_name\n",
    "            for filename in os.listdir(person_folder):\n",
    "                img_path = os.path.join(person_folder, filename)\n",
    "                processed_img = preprocess_image(img_path)\n",
    "                if processed_img is not None:\n",
    "                    images.append(processed_img)\n",
    "                    labels.append(person_name)\n",
    "            current_label += 1\n",
    "\n",
    "    return images, labels, label_map\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "images, labels, label_map = create_face_dataset(data_folder)\n",
    "print(f\"Dataset loaded: {len(images)} images.\")\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Extract embeddings using DeepFace\n",
    "print(\"Extracting embeddings...\")\n",
    "embeddings = extract_embeddings(images)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=100, whiten=True, random_state=42)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Train a classifier\n",
    "print(\"Training classifier...\")\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "classifier.fit(embeddings_pca, labels_encoded)\n",
    "\n",
    "# Save the PCA and classifier\n",
    "import joblib\n",
    "joblib.dump(pca, \"../data/pca_model.pkl\")\n",
    "joblib.dump(classifier, \"../data/classifier_model.pkl\")\n",
    "joblib.dump(label_encoder, \"../data/label_encoder.pkl\")\n",
    "print(\"Models saved.\")\n",
    "\n",
    "# Function to predict using the trained classifier\n",
    "def predict_faces(test_folder, pca, classifier, label_encoder):\n",
    "    results = []\n",
    "\n",
    "    for filename in sorted(os.listdir(test_folder)):\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "        processed_img = preprocess_image(img_path)\n",
    "        if processed_img is None:\n",
    "            continue\n",
    "\n",
    "        embedding = extract_embeddings([processed_img])[0]\n",
    "        embedding_pca = pca.transform([embedding])\n",
    "        predicted_label = classifier.predict(embedding_pca)[0]\n",
    "        person_name = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"predicted_label\": person_name\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Load saved models for prediction\n",
    "pca = joblib.load(\"../data/pca_model.pkl\")\n",
    "classifier = joblib.load(\"../data/classifier_model.pkl\")\n",
    "label_encoder = joblib.load(\"../data/label_encoder.pkl\")\n",
    "\n",
    "# Paths for prediction\n",
    "test_folder = \"../data/faces4_test\"\n",
    "results = predict_faces(test_folder, pca, classifier, label_encoder)\n",
    "\n",
    "# Create submission file\n",
    "def create_submission_csv(results, output_csv_path, test_images_folder):\n",
    "    all_filenames = sorted(\n",
    "        [os.path.splitext(filename)[0] for filename in os.listdir(test_images_folder) \n",
    "         if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    )\n",
    "\n",
    "    grouped_dict = {result[\"filename\"].split('.')[0]: result[\"predicted_label\"] for result in results}\n",
    "\n",
    "    submission_data = []\n",
    "    for filename in all_filenames:\n",
    "        label_name = grouped_dict.get(filename, \"nothing\")\n",
    "        submission_data.append({\"image\": filename, \"label_name\": label_name})\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Submission file saved to {output_csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "test_images_folder = \"../data/images/test_images/cleaned_images\"\n",
    "output_csv_path = \"../submission.csv\"\n",
    "create_submission_csv(results, output_csv_path, test_images_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
